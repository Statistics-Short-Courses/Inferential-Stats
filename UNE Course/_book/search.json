[
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "2  Getting to Know Your Data",
    "section": "",
    "text": "2.1 Variables\nBefore we jump into the world of statistical testing, let’s take a moment to refresh our understanding of what a variable is, the different types of variables, and how we can describe them using numerical and graphical methods.\nSo what is a variable?\nThe Australian Bureau of Statistics defines a variable to be “any characteristic, number, or quantity that can be measured or counted.”\nIf you’ve ever tried dieting, you might have recorded your weight on your phone over time. Or maybe you’ve tracked how long your morning commute takes so you know when to leave to arrive on time. In both cases, you are measuring something that changes, and these are examples of variables.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting to Know Your Data</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Welcome to your journey into Inferential Statistics!\nWhether you’re a research student hoping to build on your statistical skills or just starting your journey in the field, this course will give you the tools and confidence to apply inferential statistics in R effectively.\nIn this short course, we’ll explore a variety of essential concepts and techniques used in statistical analysis and apply these tools to real datasets and problems.\nWe’ll cover key background topics such as common statistical terminology (p-values, anyone?), types of variables, and more.\nAlong the way, you’ll build confidence in creating clear, visually appealing graphs, and in knowing when and how to use them appropriately.\nFinally, we will cover some useful and common statistical tests, such as:\n\nHypothesis testing\nt-tests (one-sample, two-sample, and paired)\nChi-squared tests (goodness of fit and independence)\nANOVA",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "chapter1.html#types-of-variables",
    "href": "chapter1.html#types-of-variables",
    "title": "2  Getting to Know Your Data",
    "section": "2.2 Types of Variables",
    "text": "2.2 Types of Variables\nThere are two main types of variables:\n\nNumerical\nCategorical\n\nA numerical variable represents values to describe a measurable quantity. A numerical variable can be either discrete or continuous.\nDiscrete numerical variables take on distinct whole values, and are countable. For example, if we were to look at the at the number of cars in a parking lot, the number of birds in a tree, or the number of times “3” is rolled in a series of die rolls, these are exact values that can be counted and are thus discrete.\nContinuous numerical variables can take on any value within a range of real numbers. In other words, they can be measured to any level of precision. For example, age exists on a continuous scale because, in theory, it can be measured infinitely precisely. Someone could be 10.25, 10.257, or even 10.2576326362 years old. In everyday life, we usually round age to the nearest year, but that does not change the fact that the underlying variable is continuous. Other common examples of continuous numerical variables include weight, height, and time. Can you explain why each of these variables is numerical and continuous?\nA categorical variable, on the other hand, represents categories or labels that describe a quality or characteristic. Categorical variables can be either nominal or ordinal.\nA nominal categorical variable includes observations with no particular order. For example, if you asked ten coworkers for their favorite movie and recorded their answers under a “movies” variable, it would be nominal because there is no inherent sequence or ranking among the movie titles.\nIn an ordinal categorical variable, there is an inherent logical order to the observations. For example, if we collected age groups such as “18–24”, “25–38”, “39–55”, “56–70”, and “70+”, we’re now working with labels that have a built-in order where “18–24” is younger than “25–38”, and so on.\nAnother example might be asking people whether they like ice cream, with options like “strongly agree”, “agree”, “neutral”, “disagree”, and “strongly disagree”. In this case, the order of the options has meaning, even if the distance between them isn’t equal.\nTake a moment to check your understanding with the exercises below.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting to Know Your Data</span>"
    ]
  },
  {
    "objectID": "chapter1.html#exercise-1.1",
    "href": "chapter1.html#exercise-1.1",
    "title": "2  Chapter 1",
    "section": "2.3 Exercise 1.1",
    "text": "2.3 Exercise 1.1\n\nDescribe the following variables:\na. Eye colour is a discrete numerical variablecontinuous numerical variableordinal categorical variablenominal categorical variable\nb. Temperature is a discrete numerical variableordinal categorical variablenominal categorical variablecontinuous numerical variable\nc. The number of heads in a series of coin flips is a continuous numerical variableordinal categorical variablenominal categorical variablediscrete numerical variable\nd. Education level is a discrete numerical variablecontinuous numerical variablenominal categorical variableordinal categorical variable\ne. Postal Code is a discrete numerical variablecontinuous numerical variableordinal categorical variablenominal categorical variable\nf. Income salary is a discrete numerical variableordinal categorical variablenominal categorical variablecontinuous numerical variable\ng. Number of calls per day is a discrete numerical variablecontinuous numerical variableordinal categorical variablenominal categorical variablediscrete numerical variable",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1</span>"
    ]
  },
  {
    "objectID": "chapter1.html#graphing",
    "href": "chapter1.html#graphing",
    "title": "2  Chapter 1",
    "section": "2.4 Graphing",
    "text": "2.4 Graphing\nNo",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1</span>"
    ]
  },
  {
    "objectID": "chapter1.html#section",
    "href": "chapter1.html#section",
    "title": "2  Chapter 1",
    "section": "2.5 ",
    "text": "2.5",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chapter 1</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UNE Course",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapter1.html#exercise-checkpoint-1",
    "href": "chapter1.html#exercise-checkpoint-1",
    "title": "2  Getting to Know Your Data",
    "section": "2.3 Exercise Checkpoint 1",
    "text": "2.3 Exercise Checkpoint 1\n\nDescribe the following variables:\na. Eye colour is a discrete numerical variablecontinuous numerical variableordinal categorical variablenominal categorical variable\nb. Temperature is a discrete numerical variableordinal categorical variablenominal categorical variablecontinuous numerical variable\nc. The number of heads in a series of coin flips is a continuous numerical variableordinal categorical variablenominal categorical variablediscrete numerical variable\nd. Education level is a discrete numerical variablecontinuous numerical variablenominal categorical variableordinal categorical variable\ne. Postal Code is a discrete numerical variablecontinuous numerical variableordinal categorical variablenominal categorical variable\nf. Income salary is a discrete numerical variableordinal categorical variablenominal categorical variablecontinuous numerical variable\ng. Number of calls per day is a discrete numerical variablecontinuous numerical variableordinal categorical variablenominal categorical variablediscrete numerical variable",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting to Know Your Data</span>"
    ]
  },
  {
    "objectID": "chapter1.html#visually-representing-data",
    "href": "chapter1.html#visually-representing-data",
    "title": "2  Getting to Know Your Data",
    "section": "2.4 Visually Representing Data",
    "text": "2.4 Visually Representing Data\nNow that we’ve covered the main types of variables, we can start thinking about how to visually represent data.\nFirst, we will need to load in some data into R. We will be working with the palmerpenguins package. The palmerpenguins package is a dataset collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\nIf you have not used this package before, you will need to install it first:\n\ninstall.packages(\"palmerpenguins\")\n\nOnce installed, you will need to load the package into R.\n\nlibrary(palmerpenguins)\n\nNow that we have the package installed, let’s take a look at the variables in the dataset using str().\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nYou might notice that some values are listed as NA. This means there are missing observations. To check for missing values, we can use:\n\nany(is.na(penguins))\n\n[1] TRUE\n\n\nSince this returns TRUE, we know there are missing values in the dataset. Let’s find out how many:\n\nsum(is.na(penguins))\n\n[1] 19\n\n\nThere are 19 missing observations. This can cause problems when generating numerical summaries or running statistical tests. At this stage, to handle this, we can remove the missing values. It’s always best practice to store your cleaned data in a new dataset and leave the original untouched. Note that you should always be careful when removing observations, as even partially filled observations can still provide valuable information.\n\nclean_penguins &lt;- na.omit(penguins)\n\nWe can check the structure again to make sure everything looks good:\n\nstr(clean_penguins)\n\ntibble [333 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:333] 39.1 39.5 40.3 36.7 39.3 38.9 39.2 41.1 38.6 34.6 ...\n $ bill_depth_mm    : num [1:333] 18.7 17.4 18 19.3 20.6 17.8 19.6 17.6 21.2 21.1 ...\n $ flipper_length_mm: int [1:333] 181 186 195 193 190 181 195 182 191 198 ...\n $ body_mass_g      : int [1:333] 3750 3800 3250 3450 3650 3625 4675 3200 3800 4400 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 1 2 1 2 2 ...\n $ year             : int [1:333] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:11] 4 9 10 11 12 48 179 219 257 269 ...\n  ..- attr(*, \"names\")= chr [1:11] \"4\" \"9\" \"10\" \"11\" ...\n\n\nWe can see that there are eight variables. Three of these are categorical: species, island, and sex. These are stored as factors, where the levels represent the number of distinct labels or groups within each variable. For example, sex has two levels: male and female.\nYou’ll notice that there are four numerical variables: bill_length_mm, bill_depth_mm, flipper_length_mm, and year. If your instinct is that year doesn’t quite fit as right as a numerical variable, you would be right! It is better to treat year as a categorical variable. To convert it, we can use:\n\nclean_penguins$year &lt;- as.factor(clean_penguins$year)\n\nNow if we run str again, we can see that year is now correctly stored as a categorical variable with three levels.\n\nstr(clean_penguins)\n\ntibble [333 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:333] 39.1 39.5 40.3 36.7 39.3 38.9 39.2 41.1 38.6 34.6 ...\n $ bill_depth_mm    : num [1:333] 18.7 17.4 18 19.3 20.6 17.8 19.6 17.6 21.2 21.1 ...\n $ flipper_length_mm: int [1:333] 181 186 195 193 190 181 195 182 191 198 ...\n $ body_mass_g      : int [1:333] 3750 3800 3250 3450 3650 3625 4675 3200 3800 4400 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 1 2 1 2 2 ...\n $ year             : Factor w/ 3 levels \"2007\",\"2008\",..: 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:11] 4 9 10 11 12 48 179 219 257 269 ...\n  ..- attr(*, \"names\")= chr [1:11] \"4\" \"9\" \"10\" \"11\" ...\n\n\nIf you’re interested in seeing the unique groupings or labels within a categorical variable, you can use the unique() function.\n\nunique(clean_penguins$year)\n\n[1] 2007 2008 2009\nLevels: 2007 2008 2009\n\n\nThis shows that the data was collected over the years 2007, 2008, and 2009.\nYou can also see from the structure output str() that the penguins dataset is stored as a 333 x 8 tibble, which is a type of data frame in R. This means that there are 333 rows (observations) and 8 columns (variables).\nWe can confirm this using the dim() function.\n\ndim(clean_penguins)\n\n[1] 333   8\n\n\nIf you wish to have a closer look at inspecting the penguins dataset, you can use the View() function to open it in a new tab on RStudio.\n\nView(penguins)\nView(clean_penguins)\n\nNow that we’ve inspected the dataset, we can start thinking about how to visually represent and understand the data.\nWe can describe data using numerical summaries and graphs. Numerical summaries are statistical measures that capture key aspects of a dataset. The way we choose to present these summaries and the graphs that accompany them depends on the type of variable we are working with.\nLet’s start with numerical summaries.\nFor numerical variables, whether continuous or discrete, we can include:\n\nmean\nstandard deviation\nmedian\nminimum\nmaximum\nInterquartile Range (IQR)\n\nIMPORTANT NOTE: When reporting descriptive statistics, always provide appropriate context. If you report a mean, include the standard deviation, and vice versa. If you report a median, include the interquartile range (IQR), and vice versa. Likewise, if you report a maximum value, always include the minimum to give full perspective.\nSome helpful R functions for generating summary statistics:\n\n\n\n\n\n\n\n\nSummary Statistic\nCommand\n\n\n\n\nMean\nmean(...)\n\n\nStandard Deviation\nsd(...)\n\n\nMedian\nmedian(...)\n\n\nMinimum\nmin(...)\n\n\nMaximum\nmax(...)\n\n\nInterquartile Range\nIQR(...)\n\n\nFirst quartile\nquantile(..., 0.25)\n\n\nThird quartile\nquantile(..., 0.75)\n\n\nFive point summary\nsummary(...)\n\n\n\n\n\n\n\nLet’s take a look at calculating descriptive statistics for body_mass_g, which describes the body mass of each penguin in grams.\nNow we can attach the cleaned penguins dataset. Attaching the dataset allows us to call variables directly by name. If we don’t attach it, we can still access variables, but we need to use the full format (for example, clean_penguins$sex).\n\n# Attach cleaned dataset \nattach(clean_penguins)\n\n\n# Let's first calculate the mean and round it to one decimal place\nround(mean(body_mass_g),1)\n\n[1] 4207.1\n\n# Now we can calculate the standard deviation\nround(sd(body_mass_g),1)\n\n[1] 805.2\n\n\nThe average body mass of penguins is 4207.1 g, with a standard deviation of 805.2 g.\n\n# calculate the minimum\nmin(body_mass_g)\n\n[1] 2700\n\n# calculate the maximum\nmax(body_mass_g)\n\n[1] 6300\n\n\nThe minimum observed body mass is 2700 g, and the maximum observed body mass is 6300 g.\n\n# calculate median\nmedian(body_mass_g)\n\n[1] 4050\n\n# calculate IQR\n## first quantile\nquantile(body_mass_g, 0.25)\n\n 25% \n3550 \n\n## third quantile \nquantile(body_mass_g, 0.75)\n\n 75% \n4775 \n\n\nThe median body mass is 4050 g, with an interquartile range from 3350 g to 4775 g.\nThe summary() function lets us quickly gather all of this information at once.\n\n# Calculate 5-point summary\nsummary(body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2700    3550    4050    4207    4775    6300 \n\n\nNow that we’ve explored numerical summaries, let’s move on to graphing.\nWhen you have one numerical variable, whether discrete or continuous, a histogram is a great way to visualise its distribution.\nWe’ll use the ggplot2 package for this. If you haven’t used it before, you’ll need to install it first.\n\n# Install the package\ninstall.packages(ggplot2)\n\nOnce installed, you can load the package and start plotting.\n\n# Load the library\nlibrary(ggplot2)\n\n# We can plot the histogram\nggplot(clean_penguins, aes(x=body_mass_g))+\n  geom_histogram()\n\n\n\n\n\n\n\n\nThe histogram looks a bit plain without any color, and the x-axis label isn’t very informative. Let’s add some color, fix the labels, and give it a clean white background.\n\n# We can plot the histogram\nggplot(clean_penguins, aes(x=body_mass_g))+\n  geom_histogram(fill=\"orangered\", bins=30) +\n  labs(x=\"Body Mass of Penguins (g)\")+\n  theme_bw()\n\n\n\n\n\n\n\n\nWhat if we’re interested in how body mass relates to flipper length? In this case, we’re working with two continuous numerical variables, so a scatterplot would be a good choice.\n\nggplot(clean_penguins, aes(x=body_mass_g, y=flipper_length_mm))+\n  geom_point()\n\n\n\n\n\n\n\n\nLike we did with the histogram, we can add color, change the shape of the points, and include informative labels.\n\nggplot(clean_penguins, aes(x=body_mass_g, y=flipper_length_mm))+\n  geom_point(fill=\"aquamarine\", col=\"aquamarine4\", pch=21, size=2.5)+\n  labs(x=\"Body Mass of Penguins (g)\", y=\"Flipper Length of Penguins (mm)\")+\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can see that as the body mass of a penguin increases, its flipper length also tends to increase. This suggests a strong positive linear relationship.\nNow, let’s look at a case where we have one categorical variable and one numerical variable. A boxplot is a great choice here. Let’s see how body mass differs between penguin species.\n\nggplot(clean_penguins, aes(x=species, y=body_mass_g))+\n  geom_boxplot(fill = c(\"coral2\", \"chartreuse2\", \"cadetblue2\"),\n               col = c(\"coral3\", \"chartreuse4\", \"cadetblue4\")) +\n  labs(x=\"Species of Penguin\", y=\"Body Mass (g)\")\n\n\n\n\n\n\n\n\nWe can see that Gentoo penguins have a noticeably higher median body mass compared to Chinstrap and Adelie penguins. The interquartile range (the box) for the Gentoo species does not overlap with the others, suggesting there may be a significant difference between them.\nSince we’re now considering species, let’s also take a look at how many penguins were observed in each species. Because we’re dealing with a categorical variable, a bar plot is appropriate.\n\nggplot(clean_penguins, aes(x = species)) +\n  geom_bar(fill = c(\"coral2\", \"chartreuse2\", \"cadetblue2\"),\n               col = c(\"coral3\", \"chartreuse4\", \"cadetblue4\")) +\n  labs(x = \"Penguin Species\", y = \"Count\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can also explore proportions to understand how each species contributes to the total sample.\n\nggplot(data=clean_penguins, aes(x=species))+\n  geom_bar(fill = c(\"coral2\", \"chartreuse2\", \"cadetblue2\"),\n               col = c(\"coral3\", \"chartreuse4\", \"cadetblue4\"), \n           aes(y=after_stat(prop), group=1))+\n  labs(x=\"Penguin Species\", y=\"Proportion\")+\n  theme_bw()\n\n\n\n\n\n\n\n\nAdelie penguins make up a much larger proportion of the sample, while Chinstrap penguins account for the smallest. It’s important to consider how such imbalances in your dataset could influence your interpretation.\nWe can also generate a mosaic plot for species. To do so, we will need to install ggmosaic.\n\ninstall.packages(\"ggmosaic\")\n\n\nlibrary(ggmosaic)\n\nggplot(data=clean_penguins, aes(col=species))+\n  geom_mosaic(aes(x=product(species)), fill=c(\"coral2\", \"chartreuse2\", \"cadetblue2\"))+\n  theme_bw() \n\n\n\n\n\n\n\n\nThe wider the tile, the greater the proportion that species contributes. Adelie has the widest tile, which confirms it makes up the largest share of the sample.\nWhat if we want to look at penguin species by the island where they were observed? We are now dealing with two categorical variables. Mosaic plots work well here too.\n\nggplot(clean_penguins) +\n  geom_mosaic(aes(x = product(island, species)), \n              fill = rep(c(\"coral2\", \"chartreuse2\", \"cadetblue2\"),3)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nFrom this plot you can see:\n\nAdelie appear on Biscoe, Dream, and Torgersen in roughly similar counts.\nChinstrap are observed only on Dream.\nGentoo are observed only on Biscoe.\n\nThese patterns help explain why Adelie dominate overall, and they also show that species presence varies by island.\nBe sure to detach() your dataset before you move onto the exercises.\n\ndetach(clean_penguins)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting to Know Your Data</span>"
    ]
  },
  {
    "objectID": "chapter1.html#exercise-checkpoint-2",
    "href": "chapter1.html#exercise-checkpoint-2",
    "title": "2  Getting to Know Your Data",
    "section": "2.5 Exercise Checkpoint 2",
    "text": "2.5 Exercise Checkpoint 2\n\nNow that you are more comfortable generating plots and summary statistics in R, it is a good time to test your skills on a new dataset, the built-in iris dataset. This dataset is already preloaded in RStudio, so there is no need to import anything.\nTo make sure it is available, you can view it by running\n\nView(iris)\n\nThis will open the dataset in a new tab in RStudio so you can explore its structure and variables before starting your analysis.\na. How many variables are in the iris dataset? \nb. How many observations are in the iris dataset? \nc. How many categorical variables are in the iris dataset? \nd. How many numerical variables are in the iris dataset? \ne. How many species are in the iris dataset? \nf. What are the names of the three species in the iris dataset? Please list them in alphabetical order, separated by commas (for example: x, y, z) \ng. Is Species nominal or ordinal? \nh. Is Sepal.Length continuous or discrete? \ni. What is the mean sepal width of iris varieties rounded to one decimal place? \nj. What is an appropriate plot to visualise petal width against species? \nk. What is an appropriate plot to visualise petal width against sepal width?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting to Know Your Data</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "3  Probability Distributions",
    "section": "",
    "text": "3.1 The Normal Distribution\nIn the previous chapter, we’ve described what we see in data. Understanding probability can help us reason about what we expect from our data.\nA random variable is a variable whose value is determined by chance. For example, if we are looking at the number of heads in a series of coin flips, then the number of heads is a random variable.\nA probability distribution is a model that describes the likelihood of each outcome. If we know what type of distribution to expect based on the kind of experiment or observation we are doing, we can model the probability or chance of those outcomes. In the case of counting the number of heads in a series of coin flips, this is known as a Bernoulli trial because each head can be counted as a success. The number of successes in several independent Bernoulli trials can be modeled by the binomial distribution. We will look at this in more detail later.\nA normal distribution is a continuous, symmetric, bell-shaped probability distribution defined by a mean (\\(\\mu\\)) and standard deviation (\\(\\sigma\\)). Normal distributions have:\nThis is also known as the 68-85-99.7 rule. This means that if you know the mean and the standard deviation of a normal data set you can calculate the range of values in which 68%, 95% and 99.7% of the data will fall.\nA standard normal distribution is a special case of the normal distribution that has a mean of 0 and a standard deviation of 1, which is denoted as \\(Z \\sim N(0,1)\\) where \\(Z\\) represents a standarised random variable . If the random variable is not represented by \\(Z\\) and is represented by \\(X\\) or any other letter, it is generally not a standardised normal variable. That is, \\(X \\sim (\\mu, \\sigma^2)\\). You can convert any normal variable \\(X\\) to a standard normal variable using:\n\\(Z=\\frac{X-\\mu}{\\sigma}\\)\nwhere \\(Z \\sim N(0,1)\\).\nWe might also want to find the probability of certain values occurring, which is represented by the area under the curve. For example, in a standard normal distribution, the probability that a value is greater than 2.5 (that is, \\(P(Z&gt;2.5)\\) . We can draw a graph and label the axes.\nWe know the mean is 0 and since the standard deviation is 1 that the curve approximately stretches between -3 and +3.\nNow draw in approximately where 2.5 would sit and shade in the correct part of the curve.\nLet’s work through a practical example.\nSuppose weights of the checked baggage of airline passengers follow a nearly normal distribution with mean 45 pounds and standard deviation 3.2 pounds. Most airlines charge a fee for baggage that weighs in excess of 50 pounds. How can this be expressed using probability notation P()?\nWhat is the mean?\nWhat is the standard deviation?\nWhat are the values that are 1, 2, and 3 standard deviations above the mean, in that order? Write your answers separated by commas (for example: 1, 2, 3).\nWhat are the values that are 1, 2, and 3 standard deviations below the mean, in that order? Write your answers separated by commas (for example: 1, 2, 3).\nWhich probability expression are we modelling? P(X&lt;3.2)P(X&gt;50)P(Z&gt;50)P(Z&lt;50)\nNow that we have identified the mean, standard deviation, and the type of relationship we want to model, we can start drawing our diagram. Try having a go below.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "4  Hypothesis Testing",
    "section": "",
    "text": "4.1 Foundations of Hypothesis Testing\nNow that we’re familiar with variables and probability distributions, we can start exploring hypothesis testing. Hypothesis testing provides a structured framework for approaching statistical problems and drawing conclusions from data.\nWhen performing hypothesis testing, it’s helpful to reframe the problem in the context of who, what, and why.\nLet’s refresh our understanding of a few important concepts that will be helpful in reframing our problem:\nA target population is the broader group you are interested in studying. In other words, who do you want your results to apply to?\nBecause it is usually not practical to study the entire population, we collect a sample. It is a subset of observations that represents the population.\nA response variable is the variable of interest. It is what you want to measure or understand about the population. For example, if you are studying weight change after taking a new drug, the response variable is weight.\nUsually, you are interested in comparing something about this variable, such as a mean or proportion of a population. This is called a parameter of interest.\nBecause it is often not possible or feasible to collect the actual parameter of interest, such as a population mean, we can estimate it from a sample with a point estimate, such as a sample mean or sample proportion.\nAn explanatory variable is the variable that may influence or explain changes in the response variable. In the weight example, the explanatory variable would be whether or not someone took the drug. This helps us understand why the response variable changes, in this case, why weight might increase or decrease.\nTo ensure that any observed effect (such as weight gain) is actually due to the drug and not other factors, researchers often design experiments with a control group and a treatment group. The control group does not receive the treatment, while the treatment group does. The results are then compared between the two groups.\nThe null hypothesis, denoted as \\(H_0\\), represents the baseline assumption that there is no difference or effect. In the context of our drug example, this would mean that taking the drug does not influence weight.\nThe alternative hypothesis, denoted as \\(H_a\\)​, represents the belief that there is a real difference or effect. For the drug example, this would mean that taking the drug does have a significant influence on weight.\nTest your understanding with the exercise below.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "chapter3.html#foundations-of-hypothesis-testing",
    "href": "chapter3.html#foundations-of-hypothesis-testing",
    "title": "4  Hypothesis Testing",
    "section": "",
    "text": "Target population and sample\nExplanatory and response variables\nControl and treatment\nNull and Alternative hypotheses",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "chapter3.html#exercise-checkpoint-1",
    "href": "chapter3.html#exercise-checkpoint-1",
    "title": "4  Hypothesis Testing",
    "section": "4.2 Exercise Checkpoint 1",
    "text": "4.2 Exercise Checkpoint 1\n\nTest your understanding with the exercise below.\nUNE Sport is trialing a new get-fit training program for UNE students and wants to verify whether the program improves the fitness of the participants.\nOne hundred randomly chosen students are going to take 1 hour boot camp sessions 3 times a week for 4 weeks. At both the start and end of the month all students are going to be tested for the time in which they can run the 100m. The difference in this sprint time will be recorded.\nMatch the terms below with the correct options:\nNow, think about the hypotheses:\nWhat is the alternative hypothesis for the UNE Sport bootcamp study?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "chapter2.html#the-normal-distribution",
    "href": "chapter2.html#the-normal-distribution",
    "title": "3  Probability Distributions",
    "section": "",
    "text": "approximately 68% of data points within 1 standard deviation of the mean\napproximately 95% of data points within 2 standard deviations of the mean\napproximately 99.7% (i.e., almost all) data points within 3 standard deviation of the mean\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\nWe are looking for \\(P(X&gt;50)\\), where \\(X \\sim (45, 3.2^2)\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "chapter2.html#exercise-checkpoint-1",
    "href": "chapter2.html#exercise-checkpoint-1",
    "title": "3  Probability Distributions",
    "section": "3.2 Exercise Checkpoint 1",
    "text": "3.2 Exercise Checkpoint 1\n\nPractice drawing\na. P(Z &lt; −1.35)\nb. P(Z &gt; 1.48)\nc. P(−0.4 &lt; Z &lt; 1.5)\nd. P(|Z| &gt; 2)\ne.\n\nIn the previous chapter, we learnt about discrete and continuous numerical variables.\nYou may be familiar with the bell curve",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "chapter3.html#are-airlines-safer",
    "href": "chapter3.html#are-airlines-safer",
    "title": "4  Hypothesis Testing",
    "section": "6.1 Are airlines safer",
    "text": "6.1 Are airlines safer",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "5  t-tests: one sample and two sample",
    "section": "",
    "text": "6 One Sample t-test\nWe will be covering a number of statistical tests throughout this course. Which statistical test you choose, depends on the type of experiment or study has been conducted and what type of data we have. In this chapter, we will specifically focus on applying one-sample and two-sample t-tests.\nInstead of using the normal (Z) distribution, t-tests use the t-distribution. This is because t-tests are usually based on smaller sample sizes, so we need to account for extra uncertainty in the standard error and critical values. As the sample size gets bigger, the t-distribution becomes almost identical to the Z-distribution, as can be seen below.\nLike the previous chapter, we can use a hypothesis testing framework to approach our research questions.\nBefore starting this lesson, you’ll need to download some data.\nLet’s apply our skills to some real data provided by the NSW Government, and see how even the skills we have learnt in three chapters can already be useful to the real world.\nData.NSW is an open data poral with over 16,724 NSW public sector datasets to download. You can also access additional Open Data Portals listed here:\nWe will look at the 2023 Early Childhood Education and Care (ECEC) survey. This survey collected responses from around 2,000 NSW parents and carers during January and February 2023, and was designed to understand which policy options families value most and what barriers affect their access to early childhood education and care. The dataset includes a broad mix of information: demographics, employment patterns, commuting times, childcare usage, costs, and satisfaction ratings. Because it contains both continuous and categorical variables, it provides a useful starting point for learning how to apply statistical tests to real-world data.\nWorking with real survey data can be messy, so we will go step by step and decide what needs cleaning and what does not. We’ll begin by loading the required packages and importing the dataset.\nlibrary(dplyr) \nlibrary(tidyr) \nlibrary(ggplot2)  \necec &lt;- read.csv(\"Data sets/ecec-survey-2023.csv\")\nLet’s take a look at the first six rows.\nstr(ecec)\n\n'data.frame':   2015 obs. of  678 variables:\n $ Row                 : int  1 2 3 4 5 6 7 8 9 10 ...\n $ CaseID              : int  1 2 3 4 5 6 7 8 9 10 ...\n $ RecallCode          : chr  \"af0c9b6f-d7bb-4763-a47f-1684ec1b9024\" \"31c60a20-c8ef-4114-bcc8-59151000fff1\" \"8dba2e62-a33f-4974-8bdf-9ebfcdfc0216\" \"711984d0-d943-405e-9fab-267a4e8e4087\" ...\n $ Segment6            : chr  \"Non User Sydney\" \"Non User Sydney\" \"Full User Other NSW\" \"Full User Sydney\" ...\n $ SubmittedDate       : chr  \"24-Jan-23\" \"24-Jan-23\" \"24-Jan-23\" \"24-Jan-23\" ...\n $ ResponseTimeMinutes : num  33.37 15.59 11.81 14.05 7.35 ...\n $ BWS_BLOCK           : chr  \"Block 4\" \"Block 1\" \"Block 3\" \"Block 3\" ...\n $ DCE_BLOCK           : chr  \"Block 5\" \"Block 9\" \"Block 8\" \"Block 9\" ...\n $ SQ1                 : chr  \"Male\" \"Male\" \"Female\" \"Female\" ...\n $ SQ1_OTH             : logi  NA NA NA NA NA NA ...\n $ SQ2                 : int  1978 1999 1989 1977 1990 2000 2003 1978 1989 1978 ...\n $ SQ3                 : chr  \"Sydney\" \"Sydney\" \"Other NSW\" \"Sydney\" ...\n $ SQ4                 : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ SQ5                 : chr  \"Yes, I am the parent and have childcare responsibilities\" \"Yes, I am the parent and have childcare responsibilities\" \"Yes, I am the parent and have childcare responsibilities\" \"Yes, I am the parent and have childcare responsibilities\" ...\n $ SQ6_1               : int  1 1 0 0 1 1 1 1 0 0 ...\n $ SQ6_2               : int  0 0 0 0 1 0 0 0 0 1 ...\n $ SQ6_3               : int  0 0 1 1 0 0 0 0 1 0 ...\n $ SQ6_4               : int  1 0 0 1 0 0 0 0 0 0 ...\n $ SQ6_5               : int  0 0 0 0 0 0 0 2 0 0 ...\n $ SQ6_6               : int  0 0 0 1 0 0 1 2 0 0 ...\n $ GROUP               : chr  \"ECEC non-user household\" \"ECEC non-user household\" \"ECEC full user household\" \"ECEC full user household\" ...\n $ TXTREP1             : chr  \"Please fill in the table below for each child under the age of 18, from the youngest to the oldest.\" \"Please fill in the table below for your child under the age of 18.\" \"Please fill in the table below for your child under the age of 18.\" \"Please fill in the table below for each child under the age of 18, from the youngest to the oldest.\" ...\n $ A1_1                : chr  \"June\" \"January\" \"November\" \"January\" ...\n $ A1_2                : int  2010 2018 2018 2006 2021 2020 2019 2006 2021 2018 ...\n $ A1_3                : chr  \"Female\" \"Male\" \"Female\" \"Male\" ...\n $ A1_4                : chr  \"No\" \"No\" \"Yes, this Child has a Major Health Issue\" \"No\" ...\n $ A1_5                : chr  \"No\" \"No\" \"Yes, I receive financial support from the government for this child (other than the Child Care Subsidy)\" \"No\" ...\n $ A2_1                : chr  \"March\" \"\" \"\" \"March\" ...\n $ A2_2                : int  2019 NA NA 2010 2021 NA 2004 2007 NA NA ...\n $ A2_3                : chr  \"Female\" \"\" \"\" \"Male\" ...\n $ A2_4                : chr  \"No\" \"\" \"\" \"No\" ...\n $ A2_5                : chr  \"\" \"\" \"\" \"No\" ...\n $ A3_1                : chr  \"\" \"\" \"\" \"February\" ...\n $ A3_2                : int  NA NA NA 2019 NA NA NA 2012 NA NA ...\n $ A3_3                : chr  \"\" \"\" \"\" \"Female\" ...\n $ A3_4                : chr  \"\" \"\" \"\" \"No\" ...\n $ A3_5                : chr  \"\" \"\" \"\" \"No\" ...\n $ A4_1                : chr  \"\" \"\" \"\" \"\" ...\n $ A4_2                : int  NA NA NA NA NA NA NA 2014 NA NA ...\n $ A4_3                : chr  \"\" \"\" \"\" \"\" ...\n $ A4_4                : chr  \"\" \"\" \"\" \"\" ...\n $ A4_5                : chr  \"\" \"\" \"\" \"\" ...\n $ A5_1                : chr  \"\" \"\" \"\" \"\" ...\n $ A5_2                : int  NA NA NA NA NA NA NA 2021 NA NA ...\n $ A5_3                : chr  \"\" \"\" \"\" \"\" ...\n $ A5_4                : chr  \"\" \"\" \"\" \"\" ...\n $ A5_5                : chr  \"\" \"\" \"\" \"\" ...\n $ A6_1                : chr  \"\" \"\" \"\" \"\" ...\n $ A6_2                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ A6_3                : chr  \"\" \"\" \"\" \"\" ...\n $ A6_4                : chr  \"\" \"\" \"\" \"\" ...\n $ A6_5                : chr  \"\" \"\" \"\" \"\" ...\n $ A7_1                : chr  \"\" \"\" \"\" \"\" ...\n $ A7_2                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ A7_3                : chr  \"\" \"\" \"\" \"\" ...\n $ A7_4                : chr  \"\" \"\" \"\" \"\" ...\n $ A7_5                : chr  \"\" \"\" \"\" \"\" ...\n $ A8_1                : chr  \"\" \"\" \"\" \"\" ...\n $ A8_2                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ A8_3                : chr  \"\" \"\" \"\" \"\" ...\n $ A8_4                : chr  \"\" \"\" \"\" \"\" ...\n $ A8_5                : chr  \"\" \"\" \"\" \"\" ...\n $ A9_1                : logi  NA NA NA NA NA NA ...\n $ A9_2                : logi  NA NA NA NA NA NA ...\n $ A9_3                : logi  NA NA NA NA NA NA ...\n $ A9_4                : logi  NA NA NA NA NA NA ...\n $ A9_5                : logi  NA NA NA NA NA NA ...\n $ Q1_1                : chr  \"YES\" \"YES\" \"\" \"\" ...\n $ Q1_2                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q1_3                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q1_4                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q1_5                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q1_6                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q1_7                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q1_8                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q1_OTH              : chr  \"\" \"\" \"\" \"\" ...\n $ Q1N                 : chr  \"1\" \"1\" \"\" \"\" ...\n $ Q2_1                : int  100 100 NA NA 100 100 35 100 NA NA ...\n $ Q2_2                : int  NA NA NA NA NA NA 65 NA NA NA ...\n $ Q2_3                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q2_4                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q2_5                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q2_6                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q2_7                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q2_8                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q3_1                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q3_2                : chr  \"NO\" \"NO\" \"\" \"\" ...\n $ Q3_3                : chr  \"YES\" \"YES\" \"\" \"\" ...\n $ Q4                  : chr  \"\" \"\" \"\" \"\" ...\n $ Q5                  : chr  \"3\" \"4\" NA NA ...\n $ Q6_1                : int  NA NA NA NA 10 NA NA NA NA 8 ...\n $ Q6_2                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q6_3                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q6_4                : int  NA NA NA NA NA NA NA NA NA NA ...\n $ Q6N                 : int  NA NA NA NA 10 NA NA NA NA 8 ...\n $ Q7_1                : chr  \"\" \"\" \"\" \"\" ...\n $ Q7_2                : chr  \"\" \"\" \"\" \"\" ...\n $ Q7_3                : chr  \"\" \"\" \"\" \"\" ...\n $ Q7_4                : chr  \"\" \"\" \"\" \"\" ...\n  [list output truncated]\nWow! There is a lot going on. Don’t worry about the NA values you see. Missing data is extremely common in large surveys, and we’ll make sure to remove any NA entries that would interfere with our analysis.\nYou may also notice that some of the variable names aren’t very descriptive. That can happen depending on how the original survey was designed or exported. Instead of renaming everything, we’ll concentrate on the specific variables we need for our t-test. If you want to see the exact wording of the survey questions, you can refer to the questionnaire provided alongside the dataset here.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>t-tests: one sample and two sample</span>"
    ]
  },
  {
    "objectID": "chapter3.html#section-1",
    "href": "chapter3.html#section-1",
    "title": "4  Hypothesis Testing",
    "section": "6.1 ",
    "text": "6.1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "6  Paired t-test and ANOVA",
    "section": "",
    "text": "7 Hypothesis tests using the t-distribution\n\n\n\n8 Paired t-test\nThe next data set we will be using is the Respiratory Disease hospitalisations dataset provided by HealthStats NSW. You will want to ensure that you only have “Asthma” under Disease Type and “Males” and “Females” under Sex, and “NSW” for Remoteness Category selected. You can then select the Download Icon in the bottom right corner of the graph, and then select “Download Data as CSV”.\nYou can then save the file in your Datasets folder in your InferentialStats project folder that you created in the Introduction. You can give it a new name so that it is easier to call into R Studio.\nIf you open the file, you may notice that the first row is simply a title. We can ignore the title by including skip when we load in the data.\nOnce you’ve saved the file, you can load the dataset into R by typing:\n\nlibrary(ggplot2) \nlibrary(tidyverse)  \nasthma &lt;- read.csv(\"Data sets/respiratory_disease.csv\", \n                   skip = 1) \n\nWe can take a look at the data to ensure it has been loaded in correctly.\n\nstr(asthma)\n\n'data.frame':   74 obs. of  5 variables:\n $ Disease.type       : chr  \"Asthma\" \"Asthma\" \"Asthma\" \"Asthma\" ...\n $ Sex                : chr  \"Males\" \"Males\" \"Males\" \"Males\" ...\n $ Period             : chr  \"21/22\" \"20/21\" \"19/20\" \"18/19\" ...\n $ Remoteness.category: chr  \"NSW\" \"NSW\" \"NSW\" \"NSW\" ...\n $ Number             : chr  \"3,226\" \"3,578\" \"4,231\" \"5,317\" ...\n\n\n\nHow many categorical variables are there? \nHow many numerical variables are there? \nHow many observations are there? \n\nIf you open the data set, you may notice there are “Sources”, “Notes”, and “Coding” underneath the dataset. This can be problematic when we try to analyse the data. To avoid this, we can take a “subset” of the data - in other words, we are dropping these unnecessary rows we don’t need. We will also need to convert it to wide format to compare the paired data.\n\nclean_asthma &lt;- subset(asthma, Sex %in% c(\"Males\", \"Females\")) \n\nclean_asthma &lt;- clean_asthma %&gt;% \n  select(Period, Sex, Number) %&gt;% \n  mutate(Number = as.numeric(gsub(\",\", \"\", Number))) %&gt;%\n  pivot_wider(names_from = Sex, values_from = Number)\n\n\nattach(clean_asthma)\n\n\n8.0.1 Write Hypotheses\nThe dataset includes the number of asthma hospitalisations for males and females for each year from 2001 to 2022. Although the data span a long period, we are not analysing trends over time in this task. Time needs to be handled carefully in statistics because consecutive years are usually correlated, which means they are not fully independent. However, each male value has a corresponding female value for the same year, so the two observations form a natural pair. This allows us to compare males and females within each year and then look at whether these yearly differences are consistently above or below zero across the 21-year period.\nBecause we are keeping the dataset simple, a natural research question is whether there is a difference in the average number of asthma hospitalisations between males and females across these paired yearly observations.\n\\(H_0:\\) On average, there is no difference in the number of asthma hospitalisations between males and females across the 21 years.\n\\(H_A:\\) On average, there is asignificant difference in the number of asthma hospitalisations between males and females across the 21 years.\nWe can express this in mathematical notation:\n\\(H_0:\\) \\(\\mu_{diff}=0\\)\n\\(H_A:\\) \\(\\mu_{diff} \\neq 0\\)\nWhat we need to calculate the difference between the hospitalisations for male and females. We can do that with:\n\nclean_asthma$diff &lt;- (clean_asthma$Males - clean_asthma$Females)\nclean_asthma$diff\n\n [1] -356 -246 -951 -647 -504 -598 -242 -189  -23  475  195  520  295  328   67\n[16]  172  255   64 -132 -135  139\n\n\nWe can check for skewness and normality.\n\nggplot(data=clean_asthma, aes(y=diff, x=\"\"))+\n  geom_boxplot(fill=\"mistyrose\", col=\"pink4\")+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggplot(data=clean_asthma, aes(sample=diff))+\n  geom_qq(col=\"navyblue\")+\n  geom_qq_line(col=\"steelblue\")+\n  labs(x=\"Theoretical quantiles\", y=\"Sample quantiles\")+\n  theme_bw()\n\n\n\n\n\n\n\n\nWe can now run our t-test:\n\nt.test(Females, Males, paired = TRUE) \n\n\n    Paired t-test\n\ndata:  Females and Males\nt = 0.85326, df = 20, p-value = 0.4036\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -104.0871  248.1824\nsample estimates:\nmean difference \n       72.04762 \n\n\nThe p-value (\\(t_{20}=0.85326, p=0.4036\\)) is greater than 0.05, so we fail to reject the null hypothesis. Therefore, there is no difference in mean hospitalisations for asthma between males and females.\nWith 95% confidence, there are between 104 fewer hospitalisations to 248 more hospitalisations in females compared to males. Because this interval includes zero, the data do not support a real difference between the sexes. Note that if 0 was NOT in the confidence interval, this would suggest a significant difference.\n\n\n\n9 ANOVA",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Paired t-test and ANOVA</span>"
    ]
  },
  {
    "objectID": "chapter4.html#hypotheses",
    "href": "chapter4.html#hypotheses",
    "title": "5  t-tests: one sample and two sample",
    "section": "6.1 Hypotheses",
    "text": "6.1 Hypotheses\n\nPhoto by niko nguyen on Unsplash\nSQ1 represents gender, so we can go ahead and rename it to Gender.\nD6_1 represents the average commute time from home to work.\nThe average commuting time in Australia is 29 minutes, according to the Research Report 144 from the Department of Infrastructure and Regional Development. A useful research question to explore from here is whether the average commute from home to work for female carers in NSW is greater than this national benchmark.\nBefore cleaning the data, we need to set out our hypotheses.\n\\(H_0:\\) The average work commute time from home to work for female carers across NSW is not significantly different from 29 mins.\n\\(H_A:\\) The average work commute time from home to work for female carers across NSW was significantly greater than 29 mins.\nWe can express this in mathematical notation:\n\\(H_0:\\) \\(\\mu = 29\\)\n\\(H_A:\\) \\(\\mu &gt; 29\\)\nLet’s prepare the data.\n\necec_1 &lt;- ecec %&gt;%\n  rename(Gender = SQ1,\n        Work_Commute = D6_1) %&gt;%\n  select(Gender, Work_Commute) %&gt;%\n  drop_na(Gender, Work_Commute) \n\necec_1$Gender &lt;- as.factor(ecec_1$Gender)\n\nLet’s take a look at the structure of our new data set.\n\nstr(ecec_1)\n\n'data.frame':   1567 obs. of  2 variables:\n $ Gender      : Factor w/ 3 levels \"Female\",\"Male\",..: 1 1 1 2 2 1 2 1 1 1 ...\n $ Work_Commute: int  65 30 900 40 960 30 34 15 30 15 ...\n\n\nYou might notice that there are 3 levels of Gender. We can check this:\n\ntable(ecec_1$Gender)\n\n\n    Female       Male Non-binary \n       938        626          3 \n\n\nSince we only interested in female carers, we can filter the data.\n\necec_2 &lt;- ecec_1 %&gt;%\n  filter(Gender %in% \"Female\")\n\nLet’s take a look at the structure again.\n\nstr(ecec_2)\n\n'data.frame':   938 obs. of  2 variables:\n $ Gender      : Factor w/ 3 levels \"Female\",\"Male\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Work_Commute: int  65 30 900 30 15 30 15 20 45 30 ...\n\n\nDon’t worry that it says 3 levels. The data has been filtered (we can tell by comparing the observations from before filtering and after).\n\nHow many observations are there? \nHow many variables are there? \nHow many categorical variables are there? \nHow many discrete numerical variables are there? \nHow many continuous numerical variables are there? \n\nNow we can move on to checking the conditions. To start, we’ll create a few useful plots of the home-to-work commute data. These will help us assess whether the observations can reasonably be treated as independent and whether the distribution is close enough to normal for our purposes. The normality requirement becomes less strict as the sample size grows. Slight skewness is fine around n = 15, moderate skewness is acceptable around n = 30, and even strong skewness is workable once the sample size exceeds about 60.\n\n\nI need a hint\n\n\nggplot(data=ecec_2, aes(x=Work_Commute))+\n  geom_histogram(bins=12, col=\"darkseagreen4\", fill=\"darkseagreen2\")+\n  theme_bw()+\n  labs(x=\"Commute Time From Home to Work (mins)\")\n\n\n\n\n\n\n\n\n\nggplot(data=ecec_2, aes(y=Work_Commute, x=\"\"))+\n  geom_boxplot(fill=\"mediumpurple1\")+\n  theme_bw()+\n  labs(y=\"Commute Time From Home to Work (mins)\")\n\n\n\n\n\n\n\n\n\nggplot(data=ecec_2, aes(sample=Work_Commute))+\n  geom_qq()+ #This creates the points\n  geom_qq_line(col=\"firebrick1\")+ #this creates the line\n  labs(x=\"Theoretical quantiles\", y=\"Sample quantiles\")+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nggplot(data=ecec_2, aes(y=Work_Commute, x=\"\"))+\n  geom_boxplot(fill=\"mediumpurple1\")+\n  theme_bw()+\n  labs(y=\"Commute Time From Home to Work (mins)\")+\n  geom_jitter(col=\"mediumpurple4\")\n\n\n\n\n\n\n\n\nWith 938 observations, the sample size is well above the point where normality becomes a concern. The plots show that the data are strongly right-skewed with some very large outliers. With a sample this large, the Central Limit Theorem kicks in, so the mean will still have an approximately normal sampling distribution.\nFor independence, we can lean on a few simple checks. Our data represent 938 female carers in NSW, which is only a tiny fraction of the overall population of female carers in the state, so we’re safely under the 10% guideline.\nBecause this comes from what appears to be a large, population-level survey rather, it’s reasonable to treat each person’s commute time as an independent observation.\n\nNow that we’ve checked conditions, we can proceed with t-test. We can do this with one simple line of code:\n\nt.test(ecec_2$Work_Commute, mu = 29, alternative = \"greater\")\n\n\n    One Sample t-test\n\ndata:  ecec_2$Work_Commute\nt = 2.1482, df = 937, p-value = 0.01598\nalternative hypothesis: true mean is greater than 29\n95 percent confidence interval:\n 29.69916      Inf\nsample estimates:\nmean of x \n  31.9936 \n\n\n\n\nthe t-value (the statistic), the degrees of freedom (which is n-1), and the p-value: these allow us to draw our conclusion.\nthe sample mean.\nand the confidence interval – though for a 1-sided test this isn’t a priority.\n\nThe p-value (\\(t_{937}=2.1482, p=0.0.01598\\)) is less than 0.05, so we have evidence to reject the null hypothesis. Therefore, there is evidence that the mean commute time from home to work for female carers in NSW is significantly greater than 29 minutes.\nNote that if instead the alternative hypothesis had been Ha: μ&lt;29 we would instead have:\n\nt.test(ecec_2$Work_Commute, mu = 29, alternative = \"less\")\n\n\n    One Sample t-test\n\ndata:  ecec_2$Work_Commute\nt = 2.1482, df = 937, p-value = 0.984\nalternative hypothesis: true mean is less than 29\n95 percent confidence interval:\n     -Inf 34.28805\nsample estimates:\nmean of x \n  31.9936 \n\n\nor if it was Ha: μ≠29 we would have\n\nt.test(ecec_2$Work_Commute, mu = 29, alternative = \"two.sided\")\n\n\n    One Sample t-test\n\ndata:  ecec_2$Work_Commute\nt = 2.1482, df = 937, p-value = 0.03195\nalternative hypothesis: true mean is not equal to 29\n95 percent confidence interval:\n 29.25878 34.72843\nsample estimates:\nmean of x \n  31.9936 \n\n\nNOTE that you can only calculate the confidence intervals with the two sided t-test. EG alternative=\"two.sided\". If you need the confidence intervals, then you need to run this test regardless of what your alternative hypothesis is. You should use the p-value from the test that corresponds to your alternative hypothesis though.\nTherefore, using the output from the two-sided test, with 95% confidence, the average commute time from home-to-work for female carers across NSW is between 29 minutes and 35 minutes longer than the national average. Because this range does not include zero, it points to a clear difference.\nThis naturally raises other questions. For instance, because we are looking at all of NSW, it’s possible that cities like Sydney are pushing the average up. These are the kinds of patterns you could explore further with the dataset.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>t-tests: one sample and two sample</span>"
    ]
  }
]